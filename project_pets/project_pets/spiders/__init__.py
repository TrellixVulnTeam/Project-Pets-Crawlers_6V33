# This package will contain the spiders of your Scrapy project
#
# Please refer to the documentation for information on how to create and manage
# your spiders.
# from pethappy import PethappyCatFoodSpider
## Imports modules for sequentially running the crawlers
# from twisted.internet import reactor, defer
# from scrapy.crawler import CrawlerRunner
# from scrapy.utils.log import configure_logging

# import pethappy

# configure_logging()
# runner = CrawlerRunner()

# @defer.inlineCallbacks
# def crawl():
#     yield runner.crawl(pethappy.PethappyCatFoodSpider)
#     yield runner.crawl(pethappy.PethappyDogFoodSpider)
#     reactor.stop()

# crawl()
# reactor.run() #the script will block here until the last crawl call is finished
